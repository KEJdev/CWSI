{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ai\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# load the model from disk\n",
    "rf = pickle.load(open('rgb2temp_model.sav', 'rb'))\n",
    "\n",
    "def convert_rgb2temp(max_temp,min_temp,predict):\n",
    "    scaled_temp=(max_temp-min_temp)/990\n",
    "    temp=predict*scaled_temp + min_temp\n",
    "    temp=temp.round(2)\n",
    "    return temp\n",
    "\n",
    "#temp csv load\n",
    "filepath='../data/csv_ta/metainfo_train_rev2.csv'\n",
    "temp=pd.read_csv(filepath)\n",
    "\n",
    "#이부분을 변경하면 됩니다.\n",
    "#매번 다른 알고리즘으로 이미지를 리사이즈 시키면 \n",
    "#resize path 그리고 temp_resize path 두개를 다 변경하면 됩니다.\n",
    "\n",
    "#input path\n",
    "path='../data/img_ir_resize_opencv/opencv_area/%s.png'\n",
    "#output path \n",
    "savepath='../data/img_ir_resize_opencv/opencv_area_by_pred/%s.npy'\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #data save\n",
    "    for i,r in temp.iterrows():\n",
    "        min_temp=r['ir_min']\n",
    "        max_temp=r['ir_max']\n",
    "        filename=str(int(r['name']))\n",
    "        if len(filename) < 6:\n",
    "            filename='0'+filename\n",
    "        filepath=path%(filename)\n",
    "        img=Image.open(filepath)\n",
    "        img_array=np.array(img).reshape(-1,3)\n",
    "        #predict=rf.predict(img_array)\n",
    "        predict=rf.predict(img_array)\n",
    "        temp_data=convert_rgb2temp(max_temp,min_temp,predict)\n",
    "        np.save(savepath%(filename),temp_data.reshape(347,435))\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=path%(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. cv2.INTER_NEAREST - 최근방 이웃 보간법\n",
    "\n",
    " 가장 빠르지만 퀄리티가 많이 떨어집니다. 따라서 잘 쓰이지 않습니다.\n",
    "\n",
    " \n",
    "\n",
    "2. cv2.INTER_LINEAR - 양선형 보간법(2x2 이웃 픽셀 참조)\n",
    "\n",
    " 4개의 픽셀을 이용합니다.\n",
    "\n",
    " 효율성이 가장 좋습니다. 속도도 빠르고 퀄리티도 적당합니다.\n",
    "\n",
    " \n",
    "\n",
    "3. cv2.INTER_CUBIC - 3차회선 보간법(4x4 이웃 픽셀 참조)\n",
    "\n",
    " 16개의 픽셀을 이용합니다.\n",
    "\n",
    " cv2.INTER_LINEAR 보다 느리지만 퀄리티는 더 좋습니다.\n",
    "\n",
    " \n",
    "\n",
    "4. cv2.INTER_LANCZOS4 - Lanczos 보간법 (8x8 이웃 픽셀 참조)\n",
    "\n",
    " 64개의 픽셀을 이용합니다.\n",
    "\n",
    " 좀더 복잡해서 오래 걸리지만 퀄리티는 좋습니다.\n",
    "\n",
    " \n",
    "\n",
    "5. cv2.INTER_AREA - 영상 축소시 효과적\n",
    "\n",
    " 영역적인 정보를 추출해서 결과 영상을 셋팅합니다.\n",
    "\n",
    " 영상을 축소할 때 이용합니다.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "path = \"./data/img_ir/*\"\n",
    "savepath = './data/img_ir_resize_opencv/opencv_up_down/'\n",
    "\n",
    "file_list = glob.glob(path)\n",
    "file_list_png = [file for file in file_list if file.endswith(\".png\")]\n",
    "\n",
    "png_list = 0\n",
    "for i in range(len(file_list_png)):\n",
    "    im = cv2.imread(file_list_png[i], cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(im, dsize=(435*2,347*2) ,interpolation=cv2.INTER_CUBIC) # 영역보간법 \n",
    "    imgs = cv2.resize(im, dsize=(435,347) ,interpolation=cv2.INTER_AREA) # 영역보간법 \n",
    "#     cv2.imwrite(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0] +'.png', imgs)\n",
    "#     cv2.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "# load the model from disk\n",
    "rf = pickle.load(open('rgb2temp_natural2_addtrain.sav', 'rb'))\n",
    "\n",
    "def convert_rgb2temp(max_temp,min_temp,predict):\n",
    "    scaled_temp=(max_temp-min_temp)/990\n",
    "    temp=predict*scaled_temp + min_temp\n",
    "    temp=temp.round(2)\n",
    "    return temp\n",
    "\n",
    "#temp csv load\n",
    "filepath='./data/csv_ta/metainfo_train_rev2.csv'\n",
    "temp=pd.read_csv(filepath)\n",
    "\n",
    "#이부분을 변경하면 됩니다.\n",
    "#매번 다른 알고리즘으로 이미지를 리사이즈 시키면 \n",
    "#resize path 그리고 temp_resize path 두개를 다 변경하면 됩니다.\n",
    "\n",
    "#input path\n",
    "path = \"./data/img_ir_resize_opencv/opencv_area/*\"\n",
    "\n",
    "file_list = glob.glob(path)\n",
    "file_list_png = [file for file in file_list if file.endswith(\".png\")]\n",
    "\n",
    "#output path \n",
    "savepath='./data/img_ir_resize_opencv/opencv_area_by_pred/'\n",
    "\n",
    "#data save\n",
    "for i,r in temp.iterrows():\n",
    "    min_temp=r['ir_min']\n",
    "    max_temp=r['ir_max']\n",
    "    filename=str(int(r['name']))\n",
    "    if len(filename) < 6:\n",
    "        filename='0'+filename\n",
    "    \n",
    "    for j in range(len(file_list_png)):\n",
    "        img=Image.open(file_list_png[i])\n",
    "        img_array=np.array(img).reshape(-1,3)\n",
    "        #predict=rf.predict(img_array)\n",
    "        predict=rf.predict(img_array)\n",
    "        temp_data=convert_rgb2temp(max_temp,min_temp,predict)\n",
    "        print(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0])\n",
    "        np.save(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0],temp_data.reshape(347,435))\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "# load the model from disk\n",
    "rf = pickle.load(open('rgb2temp_natural2_addtrain.sav', 'rb'))\n",
    "\n",
    "def convert_rgb2temp(max_temp,min_temp,predict):\n",
    "    scaled_temp=(max_temp-min_temp)/990\n",
    "    temp=predict*scaled_temp + min_temp\n",
    "    temp=temp.round(2)\n",
    "    return temp\n",
    "\n",
    "#temp csv load\n",
    "filepath='./data/csv_ta/metainfo_train_rev2.csv'\n",
    "temp=pd.read_csv(filepath)\n",
    "\n",
    "#이부분을 변경하면 됩니다.\n",
    "#매번 다른 알고리즘으로 이미지를 리사이즈 시키면 \n",
    "#resize path 그리고 temp_resize path 두개를 다 변경하면 됩니다.\n",
    "\n",
    "#input path\n",
    "path = \"./data/img_ir_resize_opencv/opencv_cubic/*\"\n",
    "\n",
    "file_list = glob.glob(path)\n",
    "file_list_png = [file for file in file_list if file.endswith(\".png\")]\n",
    "\n",
    "#output path \n",
    "savepath='./data/img_ir_resize_opencv/opencv_cubic_by_pred/'\n",
    "\n",
    "#data save\n",
    "for i,r in temp.iterrows():\n",
    "    min_temp=r['ir_min']\n",
    "    max_temp=r['ir_max']\n",
    "    filename=str(int(r['name']))\n",
    "    if len(filename) < 6:\n",
    "        filename='0'+filename\n",
    "    \n",
    "    for j in range(len(file_list_png)):\n",
    "        img=Image.open(file_list_png[i])\n",
    "        img_array=np.array(img).reshape(-1,3)\n",
    "        #predict=rf.predict(img_array)\n",
    "        predict=rf.predict(img_array)\n",
    "        temp_data=convert_rgb2temp(max_temp,min_temp,predict)\n",
    "        print(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0])\n",
    "        np.save(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0],temp_data.reshape(347,435))\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "# load the model from disk\n",
    "rf = pickle.load(open('rgb2temp_natural2_addtrain.sav', 'rb'))\n",
    "\n",
    "def convert_rgb2temp(max_temp,min_temp,predict):\n",
    "    scaled_temp=(max_temp-min_temp)/990\n",
    "    temp=predict*scaled_temp + min_temp\n",
    "    temp=temp.round(2)\n",
    "    return temp\n",
    "\n",
    "#temp csv load\n",
    "filepath='./data/csv_ta/metainfo_train_rev2.csv'\n",
    "temp=pd.read_csv(filepath)\n",
    "\n",
    "#이부분을 변경하면 됩니다.\n",
    "#매번 다른 알고리즘으로 이미지를 리사이즈 시키면 \n",
    "#resize path 그리고 temp_resize path 두개를 다 변경하면 됩니다.\n",
    "\n",
    "#input path\n",
    "path = \"./data/img_ir_resize_opencv/opencv_lanczos4/*\"\n",
    "\n",
    "file_list = glob.glob(path)\n",
    "file_list_png = [file for file in file_list if file.endswith(\".png\")]\n",
    "\n",
    "#output path \n",
    "savepath='./data/img_ir_resize_opencv/opencv_lanczos4_by_pred/'\n",
    "\n",
    "#data save\n",
    "for i,r in temp.iterrows():\n",
    "    min_temp=r['ir_min']\n",
    "    max_temp=r['ir_max']\n",
    "    filename=str(int(r['name']))\n",
    "    if len(filename) < 6:\n",
    "        filename='0'+filename\n",
    "    \n",
    "    for j in range(len(file_list_png)):\n",
    "        img=Image.open(file_list_png[i])\n",
    "        img_array=np.array(img).reshape(-1,3)\n",
    "        #predict=rf.predict(img_array)\n",
    "        predict=rf.predict(img_array)\n",
    "        temp_data=convert_rgb2temp(max_temp,min_temp,predict)\n",
    "        print(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0])\n",
    "        np.save(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0],temp_data.reshape(347,435))\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "# load the model from disk\n",
    "rf = pickle.load(open('rgb2temp_natural2_addtrain.sav', 'rb'))\n",
    "\n",
    "def convert_rgb2temp(max_temp,min_temp,predict):\n",
    "    scaled_temp=(max_temp-min_temp)/990\n",
    "    temp=predict*scaled_temp + min_temp\n",
    "    temp=temp.round(2)\n",
    "    return temp\n",
    "\n",
    "#temp csv load\n",
    "filepath='./data/csv_ta/metainfo_train_rev2.csv'\n",
    "temp=pd.read_csv(filepath)\n",
    "\n",
    "#이부분을 변경하면 됩니다.\n",
    "#매번 다른 알고리즘으로 이미지를 리사이즈 시키면 \n",
    "#resize path 그리고 temp_resize path 두개를 다 변경하면 됩니다.\n",
    "\n",
    "#input path\n",
    "path = \"./data/img_ir_resize_opencv/opencv_up_down/*\"\n",
    "\n",
    "file_list = glob.glob(path)\n",
    "file_list_png = [file for file in file_list if file.endswith(\".png\")]\n",
    "\n",
    "#output path \n",
    "savepath='./data/img_ir_resize_opencv/opencv_up_down_by_pred/'\n",
    "\n",
    "#data save\n",
    "for i,r in temp.iterrows():\n",
    "    min_temp=r['ir_min']\n",
    "    max_temp=r['ir_max']\n",
    "    filename=str(int(r['name']))\n",
    "    if len(filename) < 6:\n",
    "        filename='0'+filename\n",
    "    \n",
    "    for j in range(len(file_list_png)):\n",
    "        img=Image.open(file_list_png[i])\n",
    "        img_array=np.array(img).reshape(-1,3)\n",
    "        #predict=rf.predict(img_array)\n",
    "        predict=rf.predict(img_array)\n",
    "        temp_data=convert_rgb2temp(max_temp,min_temp,predict)\n",
    "        print(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0])\n",
    "        np.save(savepath + file_list_png[i].split('\\\\')[1].split('.png')[0],temp_data.reshape(347,435))\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
